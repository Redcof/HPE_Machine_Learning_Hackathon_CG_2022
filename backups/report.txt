# Problem Statement

- Attacker use various fraudulent techniques to perform phishing attract while user is visiting certain websites.
- Here we have a dataset containing 30 features indicating 3 flags:
        -1 : Phishing
        0 : Suspicious
        1 : Legitimate
- We have a `Result` column in the dataset which indicates:
        -1 : Phishing
        1 : Legitimate
- Good balance between classes
- Our task is to identify whether a certain website is Legitimate(1) or Phishing(-1) based on given 30 features.


# Proposed Solution
- The given dataset does not contain any null value which is good for us.
- Our target variable is - `Result`.
- All features are categorical in nature.
- We wish to build machine learning classification model to perform our classification task

# Data Exploration
- On performing Exploratory Data Analysis(EDA), we found few features are highly correlated with the target variable.
- Distribution between the classes are as follows:
        -1 : Phishing (51%)
        1 : Legitimate (49%)
- There are 9 features is highly correlated with `Result` variable
        - Prefix_Suffix
        - SSLfinal_State
        - URL_of_Anchor

# Feature Engineering
- We have kept all the features except `key` variable
- We dropped duplicate entries form train dataset
- Encoded `Result` variable 1 and 0 where:
        - 1 is Phishing
        - 0 is Legitimate
- Encoded rest of features to `simple ordinal caterigocal` encoding using sklearn API.

# Tools
- Language: Python
- Data Processing Libraries: Pandas, Numpy
- Data Visualization Libraries: Matplotlib, Seaborn, Sweetviz
- Machine Learning Library: scikit-learn
- Platform: Google Collab
- Model Serializer: Joblib 1.1.0



# Performance Metric:
- Our idea is to keep the False Negative Rate(FNR) as low as possible.
- We took ROC_AUC as our evaluation metric.

# Approach:
- As the number of features is not too high, we started with simple logistic regression model
- We used 5 fold cross-validation. As we have almost ~5000 data,  each fold is having 1000 samples for validation
- Later we have chosen Decision Tree model for better and reliable result.
- We performed Hyperparameter tuning and Fine Tuning to find our best decision tree.
- We have saved our best decision tree model as dt6.joblib file and feature encoder object as enc.joblib file.
- Top 5 good predictors:
    Importance  Feature Name
    0.641890    SSLfinal_State
    0.104994    URL_of_Anchor
    0.053972    Prefix_Suffix
    0.042104    web_traffic
    0.035136    Links_in_tags
